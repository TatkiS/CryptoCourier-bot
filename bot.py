import os
import json
import re
import asyncio
import logging
from datetime import datetime, timedelta, timezone
from hashlib import sha256
import requests
import feedparser
from deep_translator import GoogleTranslator
from textblob import TextBlob
from dotenv import load_dotenv
from telegram.ext import Application, ContextTypes
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from aiohttp import web

# === üåç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ ===
load_dotenv()

# === üîß –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ===
TOKEN = os.getenv("BOT_TOKEN")
CHANNEL_ID = int(os.getenv("CHANNEL_ID"))
GNEWS_API_KEY = os.getenv("GNEWS_API_KEY")
GNEWS_URL = f"https://gnews.io/api/v4/search?q=crypto&lang=en&token={GNEWS_API_KEY}"
MARKETAUX_API_KEY = os.getenv("MARKETAUX_API_KEY")
MARKETAUX_URL = f"https://api.marketaux.com/v1/news/all?filter_entities=true&language=en&categories=cryptocurrency&api_token={MARKETAUX_API_KEY}"
COINGECKO_PRICE_URL = "https://api.coingecko.com/api/v3/simple/price"

CACHE_FILE = "posted_cache.json"

ASSETS = ["bitcoin", "ethereum", "binancecoin", "solana", "chainlink", "polkadot", 
          "cosmos", "avalanche-2", "near", "render-token", "aave", "uniswap", 
          "ripple", "ethereum-name-service", "thorchain", "vechain", "cardano", 
          "bitget-token", "curve-dao-token", "jupiter-exchange", "filecoin", "arbitrum"]

MAX_POSTS_PER_RUN = 5
BANNED_DOMAINS = ["biztoc.com", "pypi.org"]
IMPORTANT_KEYWORDS = ["hack", "listing", "etf", "regulation", "partnership", "lawsuit", "court"]

TOPIC_TAGS = {
    "bitcoin": "#Bitcoin", "btc": "#Bitcoin",
    "ethereum": "#Ethereum", "eth": "#Ethereum",
    "sec": "#SEC", "etf": "#ETF",
    "binance": "#Binance", "coinbase": "#Coinbase",
    "ftx": "#FTX", "bybit": "#Bybit",
    "blackrock": "#BlackRock",
    "hack": "#Hack", "exploit": "#Exploit",
    "scam": "#Scam", "fraud": "#Fraud",
    "defi": "#DeFi", "solana": "#Solana",
    "cardano": "#Cardano",
    "usdt": "#Tether", "tether": "#Tether",
    "ripple": "#XRP", "xrp": "#XRP",
    "kraken": "#Kraken",
    "regulation": "#Regulation",
    "lawsuit": "#Court", "court": "#Court",
    "ai": "#AI", "stablecoin": "#Stablecoin",
    "nft": "#NFT", "crypto": "#Crypto",
    "blockchain": "#Blockchain", "web3": "#Web3",
    "altcoin": "#Altcoins", "altcoins": "#Altcoins"
}

logging.basicConfig(level=logging.INFO)

# === üîÑ Scheduler ===
scheduler = AsyncIOScheduler()

# === üì¶ –ö–µ—à—É–≤–∞–Ω–Ω—è ===
def load_cache():
    if not os.path.exists(CACHE_FILE):
        return {"hashes": set(), "urls": set(), "titles": set(), "date": "", "posts_today": 0}
    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        return {
            "hashes": set(data.get("hashes", [])),
            "urls": set(data.get("urls", [])),
            "titles": set(data.get("titles", [])),
            "date": data.get("date", ""),
            "posts_today": data.get("posts_today", 0)
        }
    except Exception as e:
        logging.warning(f"‚ùå –ö–µ—à –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {e}")
        return {"hashes": set(), "urls": set(), "titles": set(), "date": "", "posts_today": 0}

def save_cache(cache):
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump({
            "hashes": list(cache["hashes"]),
            "urls": list(cache["urls"]),
            "titles": list(cache["titles"]),
            "date": cache.get("date", ""),
            "posts_today": cache.get("posts_today", 0)
        }, f, indent=2, ensure_ascii=False)

# === üìú –Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ ===
def sanitize_text(text: str) -> str:
    return re.sub(r"\s+", " ", re.sub(r"<.*?>|&[a-z]+;", "", text or "")).strip()

def generate_post_hash(title: str, body: str) -> str:
    return sha256(sanitize_text(title + body).encode("utf-8")).hexdigest()

def contextual_translate(title, body):
    try:
        result = GoogleTranslator(source='auto', target='uk').translate(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n–û–ø–∏—Å: {body}")
        parts = result.split("–û–ø–∏—Å:")
        return parts[0].replace("–ó–∞–≥–æ–ª–æ–≤–æ–∫:", "").strip(), parts[1].strip() if len(parts) > 1 else body
    except:
        return title, body

def create_contextual_summary(text):
    text = text.lower()
    for k in IMPORTANT_KEYWORDS:
        if k in text:
            return {
                "hack": "üö® –Ü–º–æ–≤—ñ—Ä–Ω–æ –∑–ª–æ–º –∞–±–æ –≤—Ç—Ä–∞—Ç–∞ –¥–∞–Ω–∏—Ö.",
                "etf": "üìà ETF - –ø–æ—Ç—É–∂–Ω–∏–π —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —ñ–Ω—Å—Ç–∏—Ç—É—Ü—ñ–π.",
                "lawsuit": "‚öñÔ∏è –Æ—Ä–∏–¥–∏—á–Ω—ñ —Å—É–ø–µ—Ä–µ—á–∫–∏ –º–æ–∂—É—Ç—å –∑–º—ñ–Ω–∏—Ç–∏ —Ö—ñ–¥ –ø–æ–¥—ñ–π.",
                "court": "‚öñÔ∏è –Æ—Ä–∏–¥–∏—á–Ω—ñ —Å—É–ø–µ—Ä–µ—á–∫–∏ –º–æ–∂—É—Ç—å –∑–º—ñ–Ω–∏—Ç–∏ —Ö—ñ–¥ –ø–æ–¥—ñ–π.",
                "listing": "üì¢ –ù–æ–≤–∏–π –ª—ñ—Å—Ç–∏–Ω–≥ –ø—ñ–¥–≤–∏—â—É—î –ø–æ–ø—É–ª—è—Ä–Ω—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞.",
                "partnership": "ü§ù –ü–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞ –≤—ñ–¥–∫—Ä–∏–≤–∞—é—Ç—å –Ω–æ–≤—ñ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∏."
            }.get(k, "")
    return "üìå –¶–µ –ø–æ–¥—ñ—è, —è–∫–∞ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ –º–æ–∂–µ –≤–ø–ª–∏–Ω—É—Ç–∏ –Ω–∞ –∫—Ä–∏–ø—Ç–æ—Ä–∏–Ω–æ–∫ –Ω–∞–π–±–ª–∏–∂—á–∏–º —á–∞—Å–æ–º."

def analyze_sentiment(text):
    polarity = TextBlob(text).sentiment.polarity
    return "üü¢ –ü–æ–∑–∏—Ç–∏–≤–Ω–∞" if polarity > 0.2 else "üî¥ –ù–µ–≥–∞—Ç–∏–≤–Ω–∞" if polarity < -0.2 else "üü° –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞"

def extract_tags(text):
    return " ".join(sorted({tag for kw, tag in TOPIC_TAGS.items() if kw in text.lower()} | {"#CryptoCourierUA"}))

def is_valid_news(title, body):
    return bool(title and body and len(body.split()) > 5)

def is_image_accessible(url):
    try:
        r = requests.get(url, timeout=10)
        return r.status_code == 200 and "image" in r.headers.get("Content-Type", "")
    except:
        return False

# === üì° –î–∂–µ—Ä–µ–ª–∞ –Ω–æ–≤–∏–Ω ===
def fetch_marketaux():
    try:
        r = requests.get(MARKETAUX_URL, timeout=10)
        return r.json().get("data", [])
    except:
        return []

def fetch_gnews():
    try:
        r = requests.get(GNEWS_URL, timeout=10)
        return r.json().get("articles", [])
    except:
        return []

def fetch_coinstats():
    try:
        r = requests.get("https://api.coinstats.app/public/v1/news?skip=0&limit=10&category=cryptocurrency", timeout=10)
        return r.json().get("news", [])
    except:
        return []

def fetch_rss():
    feed = feedparser.parse("https://cointelegraph.com/rss")
    return feed.entries[:10]

# === üì∞ –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –ø—É–±–ª—ñ–∫–∞—Ü—ñ—è –Ω–æ–≤–∏–Ω ===
async def post_crypto_news(context: ContextTypes.DEFAULT_TYPE):
    cache = load_cache()
    combined = []
    today = datetime.now().strftime("%Y-%m-%d")
    
    if cache.get("date") != today:
        cache.update({"date": today, "posts_today": 0})
    
    combined += [{
        "title": n.get("title", ""),
        "body": n.get("description", "") or n.get("content", ""),
        "image": n.get("imgUrl"),
        "url": n.get("link")
    } for n in fetch_coinstats()]
    
    combined += [{
        "title": g.get("title", ""),
        "body": g.get("description", "") or g.get("content", ""),
        "image": g.get("image"),
        "url": g.get("url")
    } for g in fetch_gnews()]
    
    combined += [{
        "title": m.get("title", ""),
        "body": m.get("description", "") or m.get("snippet", ""),
        "image": m.get("image_url"),
        "url": m.get("url")
    } for m in fetch_marketaux()]
    
    combined += [{
        "title": r.get("title", ""),
        "body": r.get("summary", ""),
        "image": "",
        "url": r.get("link")
    } for r in fetch_rss()]
    
    logging.info(f"üìä –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ –Ω–æ–≤–∏–Ω: {len(combined)}")
    
    posts_sent = 0
    for post in combined:
        if posts_sent >= MAX_POSTS_PER_RUN or cache["posts_today"] >= 20:
            break
        
        title = sanitize_text(post["title"])
        body = sanitize_text(post["body"])
        url = post["url"]
        
        if not is_valid_news(title, body) or any(d in url for d in BANNED_DOMAINS):
            continue
        
        post_hash = generate_post_hash(title, body)
        if post_hash in cache["hashes"] or url in cache["urls"] or title in cache["titles"]:
            continue
        
        ukr_title, ukr_body = contextual_translate(title, body)
        logic = create_contextual_summary(title + " " + body)
        sentiment = analyze_sentiment(body)
        tags = extract_tags(title + " " + body)
        
        msg = f"""üó≥Ô∏è {ukr_title}

{ukr_body}

{logic}
{sentiment}

üìä {tags}
üîó –ß–∏—Ç–∞—Ç–∏ –ø–æ–≤–Ω—ñ—Å—Ç—é: {url}"""
        
        try:
            if post["image"] and is_image_accessible(post["image"]):
                await context.bot.send_photo(chat_id=CHANNEL_ID, photo=post["image"], caption=msg, parse_mode="HTML")
            else:
                await context.bot.send_message(chat_id=CHANNEL_ID, text=msg, parse_mode="HTML")
            
            cache["hashes"].add(post_hash)
            cache["urls"].add(url)
            cache["titles"].add(title)
            cache["posts_today"] += 1
            posts_sent += 1
            save_cache(cache)
            
            await asyncio.sleep(2)  # –ü–∞—É–∑–∞ –º—ñ–∂ –ø–æ—Å—Ç–∞–º–∏
            
        except Exception as e:
            logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ –ø–æ—Å—Ç: {e}")
    
    if posts_sent == 0:
        await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text="üì≠ –°—å–æ–≥–æ–¥–Ω—ñ –Ω–æ–≤–∏–Ω, –≤–∞—Ä—Ç–∏—Ö —É–≤–∞–≥–∏, –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –°–ª—ñ–¥–∫—É–π –∑–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è–º–∏!",
            parse_mode="HTML"
        )

# === üí∞ –¶—ñ–Ω–∏ ===
async def post_price_update(context: ContextTypes.DEFAULT_TYPE):
    try:
        url = f"{COINGECKO_PRICE_URL}?ids={','.join(ASSETS)}&vs_currencies=usd"
        data = requests.get(url, timeout=10).json()
        now = datetime.now(timezone(timedelta(hours=3))).strftime('%Y-%m-%d %H:%M')
        
        prices = "\n".join(f"{sym.upper()}: ${data[sym]['usd']:,.2f}" for sym in data if 'usd' in data[sym])
        
        await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text=f"üíπ –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ü—ñ–Ω ({now})\n\nüìä –ü–æ—Ç–æ—á–Ω—ñ —Ü—ñ–Ω–∏:\n{prices}\n\n#CryptoCourierUA #–¶—ñ–Ω–∏",
            parse_mode="HTML"
        )
    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ü—ñ–Ω: {e}")

# === üì∞ Wrapper-—Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è scheduler ===
async def scheduled_post_news(app):
    """Wrapper –¥–ª—è –≤–∏–∫–ª–∏–∫—É post_crypto_news —á–µ—Ä–µ–∑ scheduler"""
    class FakeContext:
        def __init__(self, bot):
            self.bot = bot
    
    await post_crypto_news(FakeContext(app.bot))

async def scheduled_price_update(app):
    """Wrapper –¥–ª—è –≤–∏–∫–ª–∏–∫—É post_price_update —á–µ—Ä–µ–∑ scheduler"""
    class FakeContext:
        def __init__(self, bot):
            self.bot = bot
    
    await post_price_update(FakeContext(app.bot))

# === üåê HTTP Server –¥–ª—è Health Check ===
async def health_check(request):
    """Health check endpoint –¥–ª—è Render"""
    return web.Response(text="OK", status=200)

async def start_http_server():
    """–ó–∞–ø—É—Å–∫ HTTP —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è health checks"""
    app_web = web.Application()
    app_web.router.add_get('/', health_check)
    app_web.router.add_get('/health', health_check)
    
    port = int(os.getenv('PORT', 10000))
    runner = web.AppRunner(app_web)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', port)
    await site.start()
    logging.info(f"‚úÖ HTTP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–æ –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    return runner

# === üöÄ –ì–æ–ª–æ–≤–Ω–∏–π —Ü–∏–∫–ª ===
async def main():
    app = Application.builder().token(TOKEN).build()
    
    # –î–æ–¥–∞—î–º–æ –∑–∞–¥–∞—á—ñ –≤ scheduler
    scheduler.add_job(scheduled_post_news, trigger='interval', minutes=60, args=[app])
    scheduler.add_job(scheduled_price_update, trigger='cron', hour='2,6,10,14,18,22', args=[app])
    scheduler.start()
    
    # –ó–∞–ø—É—Å–∫ HTTP —Å–µ—Ä–≤–µ—Ä–∞
    http_runner = await start_http_server()
    logging.info("ü§ñ CryptoCourierUA –∑–∞–ø—É—â–µ–Ω–æ")
    
    await app.initialize()
    await app.start()
    
    try:
        while True:
            await asyncio.sleep(3600)
    except (KeyboardInterrupt, SystemExit):
        logging.info("üõë –ó—É–ø–∏–Ω–∫–∞ –±–æ—Ç–∞...")
        await http_runner.cleanup()
        await app.stop()

if __name__ == "__main__":
    asyncio.run(main())
